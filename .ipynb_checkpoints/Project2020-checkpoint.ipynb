{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "1. [Introduction](#introduction)\n",
    "\n",
    "2. [Decision Trees](#dectree)\n",
    "\n",
    "    2.1 [Preprocessing](#preproc)\n",
    "    \n",
    "    2.2 [Algorithm](#alg)\n",
    "    \n",
    "    2.3 [Predictions](#pred)\n",
    "\n",
    "3. [Neural Networks](#neural)\n",
    "    \n",
    "    2.1 [Algorithm](#alg2)\n",
    "    \n",
    "    2.2 [Predictions](#pred2)\n",
    "    \n",
    "4. [Discussion](#disc)\n",
    "    \n",
    "5. [References](#ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a name=\"introduction\"></a>\n",
    "The goal of this project is to make 2 predictive models which predict wind turbine power from wind turbine speed. The dataset features and labels (i.e. input and output values) [1](#1) that are both continuous so regression models are employed. The two models are decision tree regression and neural networks respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees <a name=\"dectrees\"></a>\n",
    "This project will use the the DecisionTreeRegressor function from the sklearn package to perform regression using Decision Trees \n",
    "\n",
    "Decision Trees work by breaking down the dataset into smaller and smaller segments while a \"decision tree\" (i.e. a node structure with tests at each node to divide the data) is developed node by node. [2](#2)\n",
    "\n",
    "This algorithm works in the same way for both classification and regression.\n",
    "\n",
    "\n",
    "### Preprocessing <a name=\"preproc\"></a>\n",
    "First the data is imported and preprocessed. The preprocessing consists in splitting up the data into feature data (x values) and labels (y values) and rehsaping the X values as the LinearRegression() from linear_model function does not take a 1D array for the X values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data \n",
    "import pandas as pd\n",
    "lin_data = pd.read_csv('powerproduction.csv')\n",
    "lin_data.head()\n",
    "\n",
    "# X and y values for regression\n",
    "X = lin_data.iloc[:, 0].values\n",
    "y = lin_data.iloc[:, 1].values\n",
    "\n",
    "# The X values are reshaped as \n",
    "# they only contain one feature\n",
    "X = X.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing often involves scaling the data and removing outliers etc. The data will not be scaled in this project so the models are as simple as possible and there is no confusion between the predicted data and the observed data. Outliers will not be removed as there is no specific reason given why they are not accurate data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm <a name=\"alg\"></a>\n",
    "The train_test_split function is defined using the model_selection module from the sklearn package. This is used to randomly split the data into training and testing data.\n",
    "The DecisionTreeRegressor function is defined and used to fit a regressor to the X_train and y_train datasets. A test size of 27% of the data is chosen (so 73% of the data is training data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.27, random_state=0)\n",
    "\n",
    "regressor = DecisionTreeRegressor();\n",
    "regressor.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions <a name=\"pred\"></a>\n",
    "The predicted values are calculated using the regressor and the X_test testing data. Then various metrics (mean absolute error, mean squared error and root mean squared error) are calculated to test the efficacy of the model. In addition, the coefficient of variation (the root mean squared error RMSE as a percentage of the mean of the observed valeus) is calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 5.822511111111111\n",
      "Mean Squared Error: 172.3565864222222\n",
      "Root Mean Squared Error: 13.128464739725747\n",
      "Mean of observed y values: 48.014584\n",
      "Coefficient of variation: 27.34266059605087\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "y_pred = regressor.predict(X_test)\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print('Mean of observed y values:', np.mean(y))\n",
    "# coefficient of variation \n",
    "print('Coefficient of variation:', (100*np.sqrt(metrics.mean_squared_error(y_test, y_pred)))/np.mean(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficient of variation is 27.44%. A good coefficient of variation is considered to be less than 25% [3](#3) so the decision tree regression model is very close to being accurate but is not quite there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks <a name=\"neural\"></a>\n",
    "This project will use the the  function from the sklearn package to perform regression using Artificial Neural Networks.\n",
    "\n",
    "Neural networks operate in a similar manner to neurons in the brain [4](#4). Nodes in the neural network are connected together and they each have an activation function which depends on the inputs (which are the outputs of the other neurons, obtained via the connections). \n",
    "\n",
    "Activation functions differ but generally they are approximately 1 when a certain threshold value has been reached and approximately 0 if that value has not been reached. In addition, the connections between the neurons have weights which amplify or diminish the outputs (in an artificial neural network these are  set to randomly chosen small numbers [5](#5)\n",
    "\n",
    "In a typical artificial neural network, there is an input layer of neurons (which have inputs not connected to any other neuron), an output layer (which have outputs not connected to any other neuron) and a hidden layer (neurons which have inputs and outputs connected to other neurons). A deep neural network has multiple hidden layers. [6](#6)\n",
    "\n",
    "Neural networks can be used to learn functions and patterns to make predictions. Tensorflow makes predictions using neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm <a name=\"alg2\"></a>\n",
    "The data preprocessed for the decision tree classifier is used again for this.\n",
    "\n",
    "The train_test_split function is defined using the model_selection module from the sklearn package. This is used to randomly split the data into training and testing data.\n",
    "\n",
    "The Input and Dense classes are imported from tensorflow.keras.layers. The input layer and the hidden layers of the neural network are created as objects of these classes.[7]\n",
    "\n",
    "There are 500 nodes in the first hidden layer of the artificial neural network. This is because there are 500 features and 500 labels to train the model on. The inputs of this layer are conntected to the outputs of the input layer (whose shape is the shape of the input data X).\n",
    "\n",
    "After this, two more hidden layers, the first with 100 neurons and the second with 50 neurons, are created. The outputs of the last hidden layer are connected to the output layer (which has only 1 neuron). \n",
    "\n",
    "The activation function in this case is the rectified linear activation function or \"relu\". It is a piecewise linear function that returns the input if the input is positive. If the input is not positive it outputs 0. [8](#8)\n",
    "\n",
    "A regression model called model is created using the Model class. It uses the mean_squared error function for the losos function and the Adam algorithm for the optimiser. [9](#9)\n",
    "\n",
    "The model is compiled as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "input_layer = Input(shape=(X.shape[1],))\n",
    "dense_layer_1 = Dense(500, activation='relu')(input_layer)\n",
    "dense_layer_2 = Dense(100, activation='relu')(dense_layer_1)\n",
    "dense_layer_3 = Dense(50, activation='relu')(dense_layer_2)\n",
    "#dense_layer_3 = Dense(50, activation='relu')(dense_layer_2)\n",
    "#dense_layer_4 = Dense(25, activation='relu')(dense_layer_3)\n",
    "#dense_layer_5 = Dense(10, activation='relu')(dense_layer_4)\n",
    "output = Dense(1)(dense_layer_3)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output)\n",
    "model.compile(loss=\"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is trained on the training data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "141/141 [==============================] - 1s 2ms/step - loss: 2047.3387 - mean_squared_error: 2047.3387 - val_loss: 428.2003 - val_mean_squared_error: 428.2003\n",
      "Epoch 2/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 738.7106 - mean_squared_error: 738.7106 - val_loss: 416.7636 - val_mean_squared_error: 416.7636\n",
      "Epoch 3/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 587.0436 - mean_squared_error: 587.0436 - val_loss: 468.5155 - val_mean_squared_error: 468.5155\n",
      "Epoch 4/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 535.7675 - mean_squared_error: 535.7675 - val_loss: 409.5840 - val_mean_squared_error: 409.5840\n",
      "Epoch 5/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 515.5409 - mean_squared_error: 515.5409 - val_loss: 413.7297 - val_mean_squared_error: 413.7297\n",
      "Epoch 6/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 794.6727 - mean_squared_error: 794.6727 - val_loss: 381.7845 - val_mean_squared_error: 381.7845\n",
      "Epoch 7/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 575.6013 - mean_squared_error: 575.6013 - val_loss: 380.6671 - val_mean_squared_error: 380.6671\n",
      "Epoch 8/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 760.2952 - mean_squared_error: 760.2952 - val_loss: 388.6189 - val_mean_squared_error: 388.6189\n",
      "Epoch 9/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 546.0020 - mean_squared_error: 546.0020 - val_loss: 373.9258 - val_mean_squared_error: 373.9258\n",
      "Epoch 10/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 425.7139 - mean_squared_error: 425.7139 - val_loss: 424.7288 - val_mean_squared_error: 424.7288\n",
      "Epoch 11/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 445.7810 - mean_squared_error: 445.7810 - val_loss: 399.4146 - val_mean_squared_error: 399.4146\n",
      "Epoch 12/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 564.8889 - mean_squared_error: 564.8889 - val_loss: 538.3748 - val_mean_squared_error: 538.3748\n",
      "Epoch 13/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 480.5662 - mean_squared_error: 480.5662 - val_loss: 386.9955 - val_mean_squared_error: 386.9955\n",
      "Epoch 14/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 475.3989 - mean_squared_error: 475.3989 - val_loss: 354.8432 - val_mean_squared_error: 354.8432\n",
      "Epoch 15/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 683.9688 - mean_squared_error: 683.9688 - val_loss: 348.3974 - val_mean_squared_error: 348.3974\n",
      "Epoch 16/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 465.5817 - mean_squared_error: 465.5817 - val_loss: 484.6344 - val_mean_squared_error: 484.6344\n",
      "Epoch 17/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 562.7332 - mean_squared_error: 562.7332 - val_loss: 351.7790 - val_mean_squared_error: 351.7790\n",
      "Epoch 18/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 362.9077 - mean_squared_error: 362.9077 - val_loss: 343.7931 - val_mean_squared_error: 343.7931\n",
      "Epoch 19/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 605.8209 - mean_squared_error: 605.8209 - val_loss: 372.2061 - val_mean_squared_error: 372.2061\n",
      "Epoch 20/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 620.4373 - mean_squared_error: 620.4373 - val_loss: 396.4767 - val_mean_squared_error: 396.4767\n",
      "Epoch 21/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 509.7178 - mean_squared_error: 509.7178 - val_loss: 428.0884 - val_mean_squared_error: 428.0884\n",
      "Epoch 22/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 702.2357 - mean_squared_error: 702.2357 - val_loss: 371.7863 - val_mean_squared_error: 371.7863\n",
      "Epoch 23/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 565.7003 - mean_squared_error: 565.7003 - val_loss: 383.3387 - val_mean_squared_error: 383.3387\n",
      "Epoch 24/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 717.4373 - mean_squared_error: 717.4373 - val_loss: 357.5695 - val_mean_squared_error: 357.5695\n",
      "Epoch 25/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 442.8922 - mean_squared_error: 442.8922 - val_loss: 398.9700 - val_mean_squared_error: 398.9700\n",
      "Epoch 26/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 666.4021 - mean_squared_error: 666.4021 - val_loss: 361.3608 - val_mean_squared_error: 361.3608\n",
      "Epoch 27/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 660.2181 - mean_squared_error: 660.2181 - val_loss: 350.0310 - val_mean_squared_error: 350.0310\n",
      "Epoch 28/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 595.2763 - mean_squared_error: 595.2763 - val_loss: 340.3934 - val_mean_squared_error: 340.3934\n",
      "Epoch 29/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 577.5262 - mean_squared_error: 577.5262 - val_loss: 389.2692 - val_mean_squared_error: 389.2692\n",
      "Epoch 30/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 605.9743 - mean_squared_error: 605.9743 - val_loss: 338.4839 - val_mean_squared_error: 338.4839\n",
      "Epoch 31/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 428.4767 - mean_squared_error: 428.4767 - val_loss: 375.8756 - val_mean_squared_error: 375.8756\n",
      "Epoch 32/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 393.2422 - mean_squared_error: 393.2422 - val_loss: 383.4902 - val_mean_squared_error: 383.4902\n",
      "Epoch 33/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 464.0286 - mean_squared_error: 464.0286 - val_loss: 345.4974 - val_mean_squared_error: 345.4974\n",
      "Epoch 34/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 525.6583 - mean_squared_error: 525.6583 - val_loss: 366.0653 - val_mean_squared_error: 366.0653\n",
      "Epoch 35/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 633.7817 - mean_squared_error: 633.7817 - val_loss: 339.7996 - val_mean_squared_error: 339.7996\n",
      "Epoch 36/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 646.2967 - mean_squared_error: 646.2967 - val_loss: 340.2740 - val_mean_squared_error: 340.2740\n",
      "Epoch 37/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 622.9943 - mean_squared_error: 622.9943 - val_loss: 379.6325 - val_mean_squared_error: 379.6325\n",
      "Epoch 38/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 500.4264 - mean_squared_error: 500.4264 - val_loss: 408.1956 - val_mean_squared_error: 408.1956\n",
      "Epoch 39/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 463.3741 - mean_squared_error: 463.3741 - val_loss: 338.5709 - val_mean_squared_error: 338.5709\n",
      "Epoch 40/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 403.6491 - mean_squared_error: 403.6491 - val_loss: 335.1578 - val_mean_squared_error: 335.1578\n",
      "Epoch 41/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 674.4226 - mean_squared_error: 674.4226 - val_loss: 350.4321 - val_mean_squared_error: 350.4321\n",
      "Epoch 42/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 645.6327 - mean_squared_error: 645.6327 - val_loss: 345.8859 - val_mean_squared_error: 345.8859\n",
      "Epoch 43/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 343.8900 - mean_squared_error: 343.8900 - val_loss: 405.4957 - val_mean_squared_error: 405.4957\n",
      "Epoch 44/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 628.6433 - mean_squared_error: 628.6433 - val_loss: 343.0662 - val_mean_squared_error: 343.0662\n",
      "Epoch 45/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 549.4990 - mean_squared_error: 549.4990 - val_loss: 351.1798 - val_mean_squared_error: 351.1798\n",
      "Epoch 46/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 398.5466 - mean_squared_error: 398.5466 - val_loss: 375.8223 - val_mean_squared_error: 375.8223\n",
      "Epoch 47/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 460.4503 - mean_squared_error: 460.4503 - val_loss: 334.4137 - val_mean_squared_error: 334.4137\n",
      "Epoch 48/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 633.7000 - mean_squared_error: 633.7000 - val_loss: 353.5235 - val_mean_squared_error: 353.5235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 436.4600 - mean_squared_error: 436.4600 - val_loss: 349.2638 - val_mean_squared_error: 349.2638\n",
      "Epoch 50/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 506.8811 - mean_squared_error: 506.8811 - val_loss: 332.0970 - val_mean_squared_error: 332.0970\n",
      "Epoch 51/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 429.3124 - mean_squared_error: 429.3124 - val_loss: 464.2436 - val_mean_squared_error: 464.2436\n",
      "Epoch 52/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 441.0710 - mean_squared_error: 441.0710 - val_loss: 401.8352 - val_mean_squared_error: 401.8352\n",
      "Epoch 53/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 429.9007 - mean_squared_error: 429.9007 - val_loss: 417.9737 - val_mean_squared_error: 417.9737\n",
      "Epoch 54/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 580.6804 - mean_squared_error: 580.6804 - val_loss: 327.8889 - val_mean_squared_error: 327.8889\n",
      "Epoch 55/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 636.7299 - mean_squared_error: 636.7299 - val_loss: 336.7153 - val_mean_squared_error: 336.7153\n",
      "Epoch 56/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 441.2066 - mean_squared_error: 441.2066 - val_loss: 333.2499 - val_mean_squared_error: 333.2499\n",
      "Epoch 57/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 598.9178 - mean_squared_error: 598.9178 - val_loss: 329.5155 - val_mean_squared_error: 329.5155\n",
      "Epoch 58/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 461.7463 - mean_squared_error: 461.7463 - val_loss: 329.3038 - val_mean_squared_error: 329.3038\n",
      "Epoch 59/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 610.2807 - mean_squared_error: 610.2807 - val_loss: 341.8796 - val_mean_squared_error: 341.8796\n",
      "Epoch 60/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 654.4613 - mean_squared_error: 654.4613 - val_loss: 326.8946 - val_mean_squared_error: 326.8946\n",
      "Epoch 61/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 670.3994 - mean_squared_error: 670.3994 - val_loss: 323.2849 - val_mean_squared_error: 323.2849\n",
      "Epoch 62/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 528.1690 - mean_squared_error: 528.1690 - val_loss: 312.7313 - val_mean_squared_error: 312.7313\n",
      "Epoch 63/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 387.3267 - mean_squared_error: 387.3267 - val_loss: 308.1123 - val_mean_squared_error: 308.1123\n",
      "Epoch 64/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 510.2942 - mean_squared_error: 510.2942 - val_loss: 335.3990 - val_mean_squared_error: 335.3990\n",
      "Epoch 65/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 688.3684 - mean_squared_error: 688.3684 - val_loss: 295.0098 - val_mean_squared_error: 295.0098\n",
      "Epoch 66/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 520.0743 - mean_squared_error: 520.0743 - val_loss: 310.1985 - val_mean_squared_error: 310.1985\n",
      "Epoch 67/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 396.9533 - mean_squared_error: 396.9533 - val_loss: 353.4388 - val_mean_squared_error: 353.4388\n",
      "Epoch 68/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 434.1670 - mean_squared_error: 434.1670 - val_loss: 280.8090 - val_mean_squared_error: 280.8090\n",
      "Epoch 69/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 705.8985 - mean_squared_error: 705.8985 - val_loss: 283.6356 - val_mean_squared_error: 283.6356\n",
      "Epoch 70/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 515.4537 - mean_squared_error: 515.4537 - val_loss: 301.4480 - val_mean_squared_error: 301.4480\n",
      "Epoch 71/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 267.6616 - mean_squared_error: 267.6616 - val_loss: 399.1141 - val_mean_squared_error: 399.1141\n",
      "Epoch 72/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 381.6541 - mean_squared_error: 381.6541 - val_loss: 315.8212 - val_mean_squared_error: 315.8212\n",
      "Epoch 73/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 478.7258 - mean_squared_error: 478.7258 - val_loss: 266.4796 - val_mean_squared_error: 266.4796\n",
      "Epoch 74/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 347.2331 - mean_squared_error: 347.2331 - val_loss: 274.7289 - val_mean_squared_error: 274.7289\n",
      "Epoch 75/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 326.9181 - mean_squared_error: 326.9181 - val_loss: 261.6192 - val_mean_squared_error: 261.6192\n",
      "Epoch 76/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 410.8442 - mean_squared_error: 410.8442 - val_loss: 267.3860 - val_mean_squared_error: 267.3860\n",
      "Epoch 77/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 534.4752 - mean_squared_error: 534.4752 - val_loss: 267.5991 - val_mean_squared_error: 267.5991\n",
      "Epoch 78/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 459.5334 - mean_squared_error: 459.5334 - val_loss: 273.1714 - val_mean_squared_error: 273.1714\n",
      "Epoch 79/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 524.9119 - mean_squared_error: 524.9119 - val_loss: 272.8956 - val_mean_squared_error: 272.8956\n",
      "Epoch 80/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 560.9930 - mean_squared_error: 560.9930 - val_loss: 295.1534 - val_mean_squared_error: 295.1534\n",
      "Epoch 81/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 619.9362 - mean_squared_error: 619.9362 - val_loss: 266.8947 - val_mean_squared_error: 266.8947\n",
      "Epoch 82/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 501.9906 - mean_squared_error: 501.9906 - val_loss: 274.3054 - val_mean_squared_error: 274.3054\n",
      "Epoch 83/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 283.5929 - mean_squared_error: 283.5929 - val_loss: 275.1121 - val_mean_squared_error: 275.1121\n",
      "Epoch 84/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 413.3801 - mean_squared_error: 413.3801 - val_loss: 262.6935 - val_mean_squared_error: 262.6935\n",
      "Epoch 85/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 629.7270 - mean_squared_error: 629.7270 - val_loss: 292.8557 - val_mean_squared_error: 292.8557\n",
      "Epoch 86/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 374.3505 - mean_squared_error: 374.3505 - val_loss: 235.3671 - val_mean_squared_error: 235.3671\n",
      "Epoch 87/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 480.3648 - mean_squared_error: 480.3648 - val_loss: 265.1734 - val_mean_squared_error: 265.1734\n",
      "Epoch 88/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 398.9084 - mean_squared_error: 398.9084 - val_loss: 264.0704 - val_mean_squared_error: 264.0704\n",
      "Epoch 89/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 461.1567 - mean_squared_error: 461.1567 - val_loss: 241.2894 - val_mean_squared_error: 241.2894\n",
      "Epoch 90/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 306.0286 - mean_squared_error: 306.0286 - val_loss: 368.1544 - val_mean_squared_error: 368.1544\n",
      "Epoch 91/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 372.3685 - mean_squared_error: 372.3685 - val_loss: 230.6788 - val_mean_squared_error: 230.6788\n",
      "Epoch 92/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 418.4435 - mean_squared_error: 418.4435 - val_loss: 260.7321 - val_mean_squared_error: 260.7321\n",
      "Epoch 93/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 446.4059 - mean_squared_error: 446.4059 - val_loss: 218.5336 - val_mean_squared_error: 218.5336\n",
      "Epoch 94/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 354.7558 - mean_squared_error: 354.7558 - val_loss: 234.7629 - val_mean_squared_error: 234.7629\n",
      "Epoch 95/200\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 274.7130 - mean_squared_error: 274.7130 - val_loss: 224.8840 - val_mean_squared_error: 224.8840\n",
      "Epoch 96/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 2ms/step - loss: 466.0610 - mean_squared_error: 466.0610 - val_loss: 371.3873 - val_mean_squared_error: 371.3873\n",
      "Epoch 97/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 325.1944 - mean_squared_error: 325.1944 - val_loss: 295.6808 - val_mean_squared_error: 295.6808\n",
      "Epoch 98/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 239.6902 - mean_squared_error: 239.6902 - val_loss: 242.2408 - val_mean_squared_error: 242.2408\n",
      "Epoch 99/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 383.4777 - mean_squared_error: 383.4777 - val_loss: 220.0522 - val_mean_squared_error: 220.0522\n",
      "Epoch 100/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 406.1250 - mean_squared_error: 406.1250 - val_loss: 325.2694 - val_mean_squared_error: 325.2694\n",
      "Epoch 101/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 230.5121 - mean_squared_error: 230.5121 - val_loss: 418.3067 - val_mean_squared_error: 418.3067\n",
      "Epoch 102/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 367.0164 - mean_squared_error: 367.0164 - val_loss: 221.6995 - val_mean_squared_error: 221.6995\n",
      "Epoch 103/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 381.2217 - mean_squared_error: 381.2217 - val_loss: 232.7829 - val_mean_squared_error: 232.7829\n",
      "Epoch 104/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 167.0523 - mean_squared_error: 167.0523 - val_loss: 257.4698 - val_mean_squared_error: 257.4698\n",
      "Epoch 105/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 267.6632 - mean_squared_error: 267.6632 - val_loss: 216.2382 - val_mean_squared_error: 216.2382\n",
      "Epoch 106/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 287.1243 - mean_squared_error: 287.1243 - val_loss: 231.7119 - val_mean_squared_error: 231.7119\n",
      "Epoch 107/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 274.4474 - mean_squared_error: 274.4474 - val_loss: 251.8449 - val_mean_squared_error: 251.8449\n",
      "Epoch 108/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 355.9406 - mean_squared_error: 355.9406 - val_loss: 239.7285 - val_mean_squared_error: 239.7285\n",
      "Epoch 109/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 235.4572 - mean_squared_error: 235.4572 - val_loss: 232.0607 - val_mean_squared_error: 232.0607\n",
      "Epoch 110/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 304.7644 - mean_squared_error: 304.7644 - val_loss: 229.5021 - val_mean_squared_error: 229.5021\n",
      "Epoch 111/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 153.1219 - mean_squared_error: 153.1219 - val_loss: 356.2526 - val_mean_squared_error: 356.2526\n",
      "Epoch 112/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 320.0042 - mean_squared_error: 320.0042 - val_loss: 223.0067 - val_mean_squared_error: 223.0067\n",
      "Epoch 113/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 393.1132 - mean_squared_error: 393.1132 - val_loss: 240.7590 - val_mean_squared_error: 240.7590\n",
      "Epoch 114/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 226.6433 - mean_squared_error: 226.6433 - val_loss: 256.2348 - val_mean_squared_error: 256.2348\n",
      "Epoch 115/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 267.6295 - mean_squared_error: 267.6295 - val_loss: 250.1544 - val_mean_squared_error: 250.1544\n",
      "Epoch 116/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 293.1280 - mean_squared_error: 293.1280 - val_loss: 375.5946 - val_mean_squared_error: 375.5946\n",
      "Epoch 117/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 292.3018 - mean_squared_error: 292.3018 - val_loss: 290.1386 - val_mean_squared_error: 290.1386\n",
      "Epoch 118/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 317.3190 - mean_squared_error: 317.3190 - val_loss: 225.0493 - val_mean_squared_error: 225.0493\n",
      "Epoch 119/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 234.3274 - mean_squared_error: 234.3274 - val_loss: 437.3249 - val_mean_squared_error: 437.3249\n",
      "Epoch 120/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 379.1112 - mean_squared_error: 379.1112 - val_loss: 565.6830 - val_mean_squared_error: 565.6830\n",
      "Epoch 121/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 384.1226 - mean_squared_error: 384.1226 - val_loss: 433.6725 - val_mean_squared_error: 433.6725\n",
      "Epoch 122/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 315.9881 - mean_squared_error: 315.9881 - val_loss: 265.8680 - val_mean_squared_error: 265.8680\n",
      "Epoch 123/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 138.6570 - mean_squared_error: 138.6570 - val_loss: 336.7275 - val_mean_squared_error: 336.7275\n",
      "Epoch 124/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 415.9480 - mean_squared_error: 415.9480 - val_loss: 228.9435 - val_mean_squared_error: 228.9435\n",
      "Epoch 125/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 279.4263 - mean_squared_error: 279.4263 - val_loss: 251.2511 - val_mean_squared_error: 251.2511\n",
      "Epoch 126/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 160.4365 - mean_squared_error: 160.4365 - val_loss: 293.9439 - val_mean_squared_error: 293.9439\n",
      "Epoch 127/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 398.7567 - mean_squared_error: 398.7567 - val_loss: 229.7117 - val_mean_squared_error: 229.7117\n",
      "Epoch 128/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 67.5641 - mean_squared_error: 67.5641 - val_loss: 509.2737 - val_mean_squared_error: 509.2737\n",
      "Epoch 129/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 262.5849 - mean_squared_error: 262.5849 - val_loss: 291.4627 - val_mean_squared_error: 291.4627\n",
      "Epoch 130/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 307.0205 - mean_squared_error: 307.0205 - val_loss: 240.3164 - val_mean_squared_error: 240.3164\n",
      "Epoch 131/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 380.6644 - mean_squared_error: 380.6644 - val_loss: 295.7145 - val_mean_squared_error: 295.7145\n",
      "Epoch 132/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 293.9348 - mean_squared_error: 293.9348 - val_loss: 265.9073 - val_mean_squared_error: 265.9073\n",
      "Epoch 133/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 222.4429 - mean_squared_error: 222.4429 - val_loss: 612.7159 - val_mean_squared_error: 612.7159\n",
      "Epoch 134/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 337.7355 - mean_squared_error: 337.7355 - val_loss: 253.9770 - val_mean_squared_error: 253.9770\n",
      "Epoch 135/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 259.4901 - mean_squared_error: 259.4901 - val_loss: 233.4468 - val_mean_squared_error: 233.4468\n",
      "Epoch 136/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 247.5889 - mean_squared_error: 247.5889 - val_loss: 256.0074 - val_mean_squared_error: 256.0074\n",
      "Epoch 137/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 251.6278 - mean_squared_error: 251.6278 - val_loss: 365.2001 - val_mean_squared_error: 365.2001\n",
      "Epoch 138/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 163.2849 - mean_squared_error: 163.2849 - val_loss: 371.1836 - val_mean_squared_error: 371.1836\n",
      "Epoch 139/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 185.1767 - mean_squared_error: 185.1767 - val_loss: 327.1364 - val_mean_squared_error: 327.1364\n",
      "Epoch 140/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 336.8247 - mean_squared_error: 336.8247 - val_loss: 235.7213 - val_mean_squared_error: 235.7213\n",
      "Epoch 141/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 267.8561 - mean_squared_error: 267.8561 - val_loss: 246.4905 - val_mean_squared_error: 246.4905\n",
      "Epoch 142/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 358.5590 - mean_squared_error: 358.5590 - val_loss: 272.0771 - val_mean_squared_error: 272.0771\n",
      "Epoch 143/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 2ms/step - loss: 321.7191 - mean_squared_error: 321.7191 - val_loss: 258.1255 - val_mean_squared_error: 258.1255\n",
      "Epoch 144/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 275.7446 - mean_squared_error: 275.7446 - val_loss: 342.0593 - val_mean_squared_error: 342.0593\n",
      "Epoch 145/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 224.0900 - mean_squared_error: 224.0900 - val_loss: 266.6375 - val_mean_squared_error: 266.6375\n",
      "Epoch 146/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 254.3511 - mean_squared_error: 254.3511 - val_loss: 237.5105 - val_mean_squared_error: 237.5105\n",
      "Epoch 147/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 192.9915 - mean_squared_error: 192.9915 - val_loss: 247.3259 - val_mean_squared_error: 247.3259\n",
      "Epoch 148/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 392.5952 - mean_squared_error: 392.5952 - val_loss: 244.3036 - val_mean_squared_error: 244.3036\n",
      "Epoch 149/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 209.0052 - mean_squared_error: 209.0052 - val_loss: 280.2098 - val_mean_squared_error: 280.2098\n",
      "Epoch 150/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 215.7078 - mean_squared_error: 215.7078 - val_loss: 322.2364 - val_mean_squared_error: 322.2364\n",
      "Epoch 151/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 193.6348 - mean_squared_error: 193.6348 - val_loss: 256.8191 - val_mean_squared_error: 256.8191\n",
      "Epoch 152/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 246.3731 - mean_squared_error: 246.3731 - val_loss: 240.3494 - val_mean_squared_error: 240.3494\n",
      "Epoch 153/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 173.3777 - mean_squared_error: 173.3777 - val_loss: 318.6581 - val_mean_squared_error: 318.6581\n",
      "Epoch 154/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 227.1343 - mean_squared_error: 227.1343 - val_loss: 246.7425 - val_mean_squared_error: 246.7425\n",
      "Epoch 155/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 277.0196 - mean_squared_error: 277.0196 - val_loss: 294.4096 - val_mean_squared_error: 294.4096\n",
      "Epoch 156/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 203.3456 - mean_squared_error: 203.3456 - val_loss: 252.9851 - val_mean_squared_error: 252.9851\n",
      "Epoch 157/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 225.5489 - mean_squared_error: 225.5489 - val_loss: 235.6572 - val_mean_squared_error: 235.6572\n",
      "Epoch 158/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 261.1121 - mean_squared_error: 261.1121 - val_loss: 224.1608 - val_mean_squared_error: 224.1608\n",
      "Epoch 159/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 157.7235 - mean_squared_error: 157.7235 - val_loss: 250.3485 - val_mean_squared_error: 250.3485\n",
      "Epoch 160/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 282.0600 - mean_squared_error: 282.0600 - val_loss: 723.0703 - val_mean_squared_error: 723.0703\n",
      "Epoch 161/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 275.2816 - mean_squared_error: 275.2816 - val_loss: 244.8474 - val_mean_squared_error: 244.8474\n",
      "Epoch 162/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 296.1937 - mean_squared_error: 296.1937 - val_loss: 276.5045 - val_mean_squared_error: 276.5045\n",
      "Epoch 163/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 241.2680 - mean_squared_error: 241.2680 - val_loss: 339.1183 - val_mean_squared_error: 339.1183\n",
      "Epoch 164/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 288.1388 - mean_squared_error: 288.1388 - val_loss: 212.2274 - val_mean_squared_error: 212.2274\n",
      "Epoch 165/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 373.5536 - mean_squared_error: 373.5536 - val_loss: 323.8586 - val_mean_squared_error: 323.8586\n",
      "Epoch 166/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 480.2553 - mean_squared_error: 480.2553 - val_loss: 215.9917 - val_mean_squared_error: 215.9917\n",
      "Epoch 167/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 245.6285 - mean_squared_error: 245.6285 - val_loss: 306.3271 - val_mean_squared_error: 306.3271\n",
      "Epoch 168/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 299.2378 - mean_squared_error: 299.2378 - val_loss: 360.1992 - val_mean_squared_error: 360.1992\n",
      "Epoch 169/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 257.0301 - mean_squared_error: 257.0301 - val_loss: 222.8263 - val_mean_squared_error: 222.8263\n",
      "Epoch 170/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 290.5055 - mean_squared_error: 290.5055 - val_loss: 222.6647 - val_mean_squared_error: 222.6647\n",
      "Epoch 171/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 212.7047 - mean_squared_error: 212.7047 - val_loss: 237.3944 - val_mean_squared_error: 237.3944\n",
      "Epoch 172/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 261.6066 - mean_squared_error: 261.6066 - val_loss: 230.4574 - val_mean_squared_error: 230.4574\n",
      "Epoch 173/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 258.7911 - mean_squared_error: 258.7911 - val_loss: 227.5630 - val_mean_squared_error: 227.5630\n",
      "Epoch 174/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 152.0073 - mean_squared_error: 152.0073 - val_loss: 218.5836 - val_mean_squared_error: 218.5836\n",
      "Epoch 175/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 410.4601 - mean_squared_error: 410.4601 - val_loss: 231.5632 - val_mean_squared_error: 231.5632\n",
      "Epoch 176/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 334.2913 - mean_squared_error: 334.2913 - val_loss: 225.5047 - val_mean_squared_error: 225.5047\n",
      "Epoch 177/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 328.0383 - mean_squared_error: 328.0383 - val_loss: 217.8910 - val_mean_squared_error: 217.8910\n",
      "Epoch 178/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 312.6746 - mean_squared_error: 312.6746 - val_loss: 241.4390 - val_mean_squared_error: 241.4390\n",
      "Epoch 179/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 172.5316 - mean_squared_error: 172.5316 - val_loss: 257.8682 - val_mean_squared_error: 257.8682\n",
      "Epoch 180/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 327.9041 - mean_squared_error: 327.9041 - val_loss: 229.0792 - val_mean_squared_error: 229.0792\n",
      "Epoch 181/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 367.2410 - mean_squared_error: 367.2410 - val_loss: 225.4077 - val_mean_squared_error: 225.4077\n",
      "Epoch 182/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 329.0631 - mean_squared_error: 329.0631 - val_loss: 228.9393 - val_mean_squared_error: 228.9393\n",
      "Epoch 183/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 231.0474 - mean_squared_error: 231.0474 - val_loss: 260.2653 - val_mean_squared_error: 260.2653\n",
      "Epoch 184/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 291.9835 - mean_squared_error: 291.9835 - val_loss: 236.6794 - val_mean_squared_error: 236.6794\n",
      "Epoch 185/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 165.3322 - mean_squared_error: 165.3322 - val_loss: 239.2426 - val_mean_squared_error: 239.2426\n",
      "Epoch 186/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 302.0700 - mean_squared_error: 302.0700 - val_loss: 355.3266 - val_mean_squared_error: 355.3266\n",
      "Epoch 187/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 226.7125 - mean_squared_error: 226.7125 - val_loss: 486.3177 - val_mean_squared_error: 486.3177\n",
      "Epoch 188/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 365.7974 - mean_squared_error: 365.7974 - val_loss: 285.7834 - val_mean_squared_error: 285.7834\n",
      "Epoch 189/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 237.3836 - mean_squared_error: 237.3836 - val_loss: 511.7754 - val_mean_squared_error: 511.7754\n",
      "Epoch 190/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 1ms/step - loss: 321.7864 - mean_squared_error: 321.7864 - val_loss: 280.6638 - val_mean_squared_error: 280.6638\n",
      "Epoch 191/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 261.3176 - mean_squared_error: 261.3176 - val_loss: 284.5138 - val_mean_squared_error: 284.5138\n",
      "Epoch 192/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 220.1524 - mean_squared_error: 220.1524 - val_loss: 240.0280 - val_mean_squared_error: 240.0280\n",
      "Epoch 193/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 333.1629 - mean_squared_error: 333.1629 - val_loss: 236.3879 - val_mean_squared_error: 236.3879\n",
      "Epoch 194/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 370.0433 - mean_squared_error: 370.0433 - val_loss: 319.0733 - val_mean_squared_error: 319.0733\n",
      "Epoch 195/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 234.3274 - mean_squared_error: 234.3274 - val_loss: 283.2810 - val_mean_squared_error: 283.2810\n",
      "Epoch 196/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 276.4833 - mean_squared_error: 276.4833 - val_loss: 361.3753 - val_mean_squared_error: 361.3753\n",
      "Epoch 197/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 205.7240 - mean_squared_error: 205.7240 - val_loss: 289.9170 - val_mean_squared_error: 289.9170\n",
      "Epoch 198/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 227.9465 - mean_squared_error: 227.9465 - val_loss: 411.4159 - val_mean_squared_error: 411.4159\n",
      "Epoch 199/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 249.2226 - mean_squared_error: 249.2226 - val_loss: 294.0989 - val_mean_squared_error: 294.0989\n",
      "Epoch 200/200\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 213.8241 - mean_squared_error: 213.8241 - val_loss: 232.9480 - val_mean_squared_error: 232.9480\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=2, epochs=200, verbose=1, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions <a name=\"pred2\"></a>\n",
    "The predicted values are calculated using the regressor and the X_test testing data as before. Then various metrics (including the coefficient of variation) are calculated to test the efficacy of the model as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 6.508903464675902\n",
      "Mean Squared Error: 210.48527312759373\n",
      "Root Mean Squared Error: 14.508110598130749\n",
      "Mean of observed y values: 48.014584\n",
      "Coefficient of variation: 30.216049769650716\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print('Mean of observed y values:', np.mean(y))\n",
    "# coefficient of variation \n",
    "print('Coefficient of variation:', (100*np.sqrt(metrics.mean_squared_error(y_test, y_pred)))/np.mean(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficient of variation in this case is 30.2%. This is close to being accurate but does not quite meet the threshold of 25% and is less than the coefficient of variation for the Decision Tree regression (which was 27.44%) and took longer than the Decision Tree algorithm which was instantaneous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion <a name=\"disc\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both models produce results that almost meet the conventional threshold for good regression models but do not meet it. The neural network was quite large (650 neurons in total) and was performed for 200 epochs but it was not sufficient and was in fact less accuate than the decision tree regression.\n",
    "\n",
    "Removal of outliers was intentionally left out of the preprocessing because there was no specific reason to do so except to improve the accuracy of the models. However, removal of outliers could improve the accuracy of the regression. This will be attempted in the \"Fundamentals of Data Analysis\" project which requires linear regression to be performed on data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References <a name=\"ref\"></a>\n",
    "[1] Medium. 2020. Some Key Machine Learning Definitions. [online] Available at: <https://medium.com/technology-nineleaps/some-key-machine-learning-definitions-b524eb6cb48> [Accessed 28 December 2020]. <a name=\"1\"></a> <br>\n",
    "[2] 2020. [online] Available at: <https://www.saedsayad.com/decision_tree_reg.html> [Accessed 28 December 2020]. <a name=\"2\"></a> <br>\n",
    "[3] Use, 1., 2020. How To Assess A Regression's Predictive Power For Energy Use - Kw Engineering. [online] kW Engineering. Available at: <https://www.kw-engineering.com/how-to-assess-a-regressions-predictive-power-energy-use/> [Accessed 28 December 2020].<a name=\"3\"></a> <br>\n",
    "[4] Medium. 2020. A BeginnerS Guide To Neural Networks: Part One. [online] Available at: <https://towardsdatascience.com/a-beginners-guide-to-neural-networks-b6be0d442fa4> [Accessed 28 December 2020].<a name=\"4\"></a> <br>\n",
    "[5] Brownlee, J., 2020. Why Initialize A Neural Network With Random Weights?. [online] Machine Learning Mastery. Available at: <https://machinelearningmastery.com/why-initialize-a-neural-network-with-random-weights/> [Accessed 28 December 2020]. <a name=\"5\"></a> <br>\n",
    "[6] Brownlee, J., 2020. What Is Deep Learning?. [online] Machine Learning Mastery. Available at: <https://machinelearningmastery.com/what-is-deep-learning/> [Accessed 28 December 2020]. <a name=\"6\"></a> <br>\n",
    "[7] Stack Abuse. 2020. Tensorflow 2.0: Solving Classification And Regression Problems. [online] Available at: <https://stackabuse.com/tensorflow-2-0-solving-classification-and-regression-problems/> [Accessed 28 December 2020]. <a name=\"7\"></a> <br>\n",
    "[8] Brownlee, J., 2020. A Gentle Introduction To The Rectified Linear Unit (Relu). [online] Machine Learning Mastery. Available at: <https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/> [Accessed 28 December 2020]. <a name=\"8\"></a> <br>\n",
    "[9] TensorFlow. 2020. Tf.Keras.Optimizers.Adam  |  Tensorflow Core V2.4.0. [online] Available at: <https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam> [Accessed 28 December 2020]. <a name=\"9\"></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
